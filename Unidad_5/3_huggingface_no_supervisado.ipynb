{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ab994d6",
      "metadata": {
        "id": "4ab994d6"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1WNLKH10YpQNNk9eeRIyYLwGkxNbNp-Mm\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a4a675",
      "metadata": {
        "id": "71a4a675"
      },
      "source": [
        "# Modelos No Supervisados de Transformers\n",
        "---\n",
        "\n",
        "En este notebook veremos algunos ejemplos de modelos no supervisados con la librería `transformers` de [HuggingFace](https://huggingface.co/).\n",
        "\n",
        "Comenzamos instalando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d33909",
      "metadata": {
        "id": "30d33909"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch] sentencepiece sacremoses sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "286a1057",
      "metadata": {
        "id": "286a1057"
      },
      "source": [
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2087a5cb",
      "metadata": {
        "id": "2087a5cb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import pipeline\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "385bd795",
      "metadata": {
        "id": "385bd795"
      },
      "source": [
        "## **1. Descripción General**\n",
        "---\n",
        "\n",
        "Los modelos de `transformers` se utilizan en aplicaciones no supervisadas de procesamiento de lenguaje natural, tales como: la codificación de contexto automática (*AutoEncoder*) y la tarea de agrupamiento de palabras (*Word Clustering*). En la codificación de contexto automático se entrena al modelo para que se reproduzca la entrada original, mientras que en la tarea de agrupamiento de palabras se utiliza el modelo para agrupar palabras similares en grupos. También, se pueden utilizar para tareas de generación de texto, como la generación de respuestas a preguntas o la generación de texto a partir de un resumen.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Zr-35kxKbh1dI4-Twn_ZWrsILTH0L62l\" width=\"80%\">\n",
        "\n",
        "Existen algunas aplicaciones no supervisadas que pueden realizarse con modelos pre-entrenados de `transformers`. Veamos algunos ejemplos:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf6b1ac",
      "metadata": {
        "id": "5bf6b1ac"
      },
      "source": [
        "## **2. Similitud Semántica**\n",
        "---\n",
        "\n",
        "La similitud semántica en procesamiento de lenguaje natural se refiere a la medida de cuán parecidos son el significado o el sentido de dos o más palabras o frases. Esto se utiliza a menudo para encontrar relaciones entre palabras en un corpus de texto o para recomendar palabras o frases similares en una aplicación de búsqueda.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16aEwcFj6WwzAl0GW1-O0sMYT3PrI1nUR\" width=\"80%\">\n",
        "\n",
        "Existen diferentes técnicas para medir la similitud semántica, incluyendo el cálculo de la similitud de coseno entre vectores de palabras, el uso de diccionarios de sinónimos y antónimos, y el uso de redes neuronales para aprender representaciones semánticas de las palabras.\n",
        "\n",
        "Veamos cómo podemos calcular la similitud semántica entre dos textos, para ello cargamos un modelo de `sentence-similarity`.\n",
        "\n",
        "> **Nota**: esto debe realizarse con `sentence_transformers` ya que aún no existe una tarea en el `pipeline` de `transformers` para similitud entre textos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc011c2b",
      "metadata": {
        "id": "bc011c2b"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb671335",
      "metadata": {
        "id": "fb671335"
      },
      "source": [
        "Cargamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e15aae",
      "metadata": {
        "id": "c9e15aae"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aac2952d",
      "metadata": {
        "id": "aac2952d"
      },
      "source": [
        "Ahora, definimos algunos textos sobre los que evaluaremos la similitud semántica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f7dbdf",
      "metadata": {
        "id": "00f7dbdf"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "        \"esto está muy difícil\",\n",
        "        \"esto está muy fácil\",\n",
        "        \"probamos algo sencillo\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5fa2f5",
      "metadata": {
        "id": "ed5fa2f5"
      },
      "source": [
        "Esto nos permite calcular _embeddings_ para cada uno de los textos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc67b9f8",
      "metadata": {
        "id": "bc67b9f8"
      },
      "outputs": [],
      "source": [
        "encodings = model.encode(texts)\n",
        "display(encodings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52941b80",
      "metadata": {
        "id": "52941b80"
      },
      "source": [
        "Para ver qué tan parecidos son, podemos usar la similitud coseno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3943835d",
      "metadata": {
        "id": "3943835d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ad6cabc",
      "metadata": {
        "id": "2ad6cabc"
      },
      "source": [
        "Veamos la similitud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557a6b61",
      "metadata": {
        "id": "557a6b61"
      },
      "outputs": [],
      "source": [
        "sim = cosine_similarity(encodings)\n",
        "display(sim.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59872f0b",
      "metadata": {
        "id": "59872f0b"
      },
      "source": [
        "Ahora, podemos visualizarla como un mapa de calor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bf938f",
      "metadata": {
        "id": "86bf938f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(pd.DataFrame(sim, index=texts, columns=texts))\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91f024d",
      "metadata": {
        "id": "f91f024d"
      },
      "source": [
        "## **3. Zero-Shot Classification**\n",
        "---\n",
        "\n",
        "La clasificación zero-shot en procesamiento de lenguaje natural es una técnica de aprendizaje automático que permite a un modelo clasificar una entrada en una categoría para la cual no se proporcionó ningún ejemplo de entrenamiento.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1hDhi_w8qQqHI0-GTQrPLP5GnikMWyGEg\" width=\"80%\">\n",
        "\n",
        "En otras palabras, el modelo se entrena con un conjunto de categorías o de forma no supervisada (_AutoEncoders_ o _embeddings_), y luego se le presentan entradas desconocidas para las que se espera que el modelo asigne una categoría. Es una técnica utilizada para clasificar entidades desconocidas, utilizando información semántica previamente aprendida.\n",
        "\n",
        "Esto se logra mediante el uso de representaciones semánticas de las palabras o frases, que se aprenden a través de técnicas como la codificación de contexto automática o el aprendizaje de embeddings de palabras. Estas representaciones se utilizan para encontrar relaciones semánticas entre las palabras de las entradas desconocidas y las categorías conocidas, permitiendo al modelo asignar una categoría a la entrada.\n",
        "\n",
        "En resumen, la clasificación zero-shot en procesamiento de lenguaje natural es una técnica avanzada que permite a los modelos clasificar entradas en categorías para las cuales no se proporcionó ningún ejemplo de entrenamiento, utilizando información semántica previamente aprendida.\n",
        "\n",
        "Veamos un ejemplo con `transformers`, instanciamos un modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89fcd3c6",
      "metadata": {
        "id": "89fcd3c6"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"zero-shot-classification\", \"Recognai/bert-base-spanish-wwm-cased-xnli\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc3f579b",
      "metadata": {
        "id": "cc3f579b"
      },
      "source": [
        "Definimos un texto que deseamos clasificar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7927714b",
      "metadata": {
        "id": "7927714b"
      },
      "outputs": [],
      "source": [
        "text = \"el algoritmo markov chain monte carlo nos permite obtener muestras de cualquier distribución de probabilidad\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9f0bd2",
      "metadata": {
        "id": "2d9f0bd2"
      },
      "source": [
        "Definimos las posibles etiquetas en las que deseamos clasificarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "567e1e2a",
      "metadata": {
        "id": "567e1e2a"
      },
      "outputs": [],
      "source": [
        "labels = [\"política\", \"computación\", \"estadística\", \"gastronomía\", \"automóviles\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7362654c",
      "metadata": {
        "id": "7362654c"
      },
      "source": [
        "Veamos las predicciones del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174774d3",
      "metadata": {
        "id": "174774d3"
      },
      "outputs": [],
      "source": [
        "res = model(text, candidate_labels=labels)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e23b052",
      "metadata": {
        "id": "5e23b052"
      },
      "source": [
        "El resultado contiene los siguientes campos:\n",
        "\n",
        "- `sequence`: texto utilizado.\n",
        "- `labels`: etiquetas ordenadas de mayor a menor coincidencia.\n",
        "- `scores`: predicción de cada una de las etiquetas obtenidas.\n",
        "\n",
        "En este caso podemos ver que las dos categorías más probables son `estadística` y `computación`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5244b1e0",
      "metadata": {
        "id": "5244b1e0"
      },
      "source": [
        "## **4. Generación de Texto**\n",
        "---\n",
        "\n",
        "Los modelos generativos basados en `transformers` son un tipo de modelo generativo del lenguaje que utiliza la arquitectura transformer para generar texto. Los modelos transformer son una variante de las redes neuronales recurrentes que utilizan atención para procesar secuencias de entrada de longitud variable.\n",
        "\n",
        "Veamos un ejemplo de generación de texto automática:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "677c1f9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "677c1f9b",
        "outputId": "645ed108-6a9b-4e09-e9c4-5e3a7d7b5e19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x792eae40d3f0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"768px\"\n",
              "            height=\"432px\"\n",
              "            src=\"https://drive.google.com/file/d/1XTEbe7WElxWfaVouuNXZSUtvBhljzCY6/preview\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#@markdown ##**Ejecute esta celda para ver el video.**\n",
        "from IPython.display import IFrame\n",
        "IFrame(\n",
        "        src=\"https://drive.google.com/file/d/1XTEbe7WElxWfaVouuNXZSUtvBhljzCY6/preview\",\n",
        "        width=\"768px\",\n",
        "        height=\"432px\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0cf1092",
      "metadata": {
        "id": "e0cf1092"
      },
      "source": [
        "Los modelos generativos basados en `transformers` se entrenan mediante un proceso donde se les proporciona un corpus de texto de entrenamiento y se les solicita que generen texto nuevo que siga la misma distribución. Durante el entrenamiento, el modelo aprende a representar las palabras y frases en el corpus de entrenamiento como vectores, y también aprende a generar texto nuevo mediante la decodificación de estos vectores.\n",
        "\n",
        "Una vez entrenado, el modelo puede ser utilizado para generar texto nuevo de forma autónoma, ya sea mediante la generación de texto a partir de un fragmento de texto inicial o en diversas aplicaciones como pregunta-respuesta o agentes conversacionales.\n",
        "\n",
        "Veamos un ejemplo con `transformers`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee194fc4",
      "metadata": {
        "id": "ee194fc4"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"text-generation\", \"flax-community/gpt-2-spanish\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "605ef09a",
      "metadata": {
        "id": "605ef09a"
      },
      "source": [
        "Definimos un texto base que usaremos para la generación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835280c5",
      "metadata": {
        "id": "835280c5"
      },
      "outputs": [],
      "source": [
        "text = \"Hola, me llamo Juan y trabajo como\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb2fc98a",
      "metadata": {
        "id": "bb2fc98a"
      },
      "source": [
        "Veamos la generación de 100 tokens nuevos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d21735",
      "metadata": {
        "id": "b1d21735"
      },
      "outputs": [],
      "source": [
        "res = model(text, max_new_tokens=100)\n",
        "print(res[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9942f9ad",
      "metadata": {
        "id": "9942f9ad"
      },
      "source": [
        "## **Recursos Adicionales**\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este taller guiado:\n",
        "\n",
        "- [Sentence Transformers](https://www.sbert.net/).\n",
        "- [Zero-Shot Classification](https://huggingface.co/tasks/zero-shot-classification).\n",
        "- [Text Generation](https://huggingface.co/tasks/text-generation)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92afdc12",
      "metadata": {
        "id": "92afdc12"
      },
      "source": [
        "## **Créditos**\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}